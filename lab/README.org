#+TITLE: Distributed Systems 1

* Lab 0 - Hello world

First of all, unzip the provided example "hello.zip".

If you use a Java IDE (Idea, Eclipse, etc.), import the provided Gradle project (hello/build.gradle)
in the IDE and try to run it. You should see the output listed below.

If you prefer using the command line and a plain text editor for programming, follow the instructions below.

1. Download and install Java SDK, Standard Edition. Version 8 is recommended for compatibility reasons.
   http://www.oracle.com/technetwork/java/javase/downloads/index.html
2. Install Gradle build tool
   https://gradle.org/install/
3. In the command line, change dir to "hello" and run the project:
      cd hello
      gradle run
4. You should see output like this (hit enter to stop the program)
#+BEGIN_CODE
[receiver] received a message from sender2: Hello from sender2
[receiver] received a message from sender3: Hello from sender3
[receiver] received a message from sender4: Hello from sender4
[receiver] received a message from sender0: Hello from sender0
[receiver] received a message from sender1: Hello from sender1
#+END_CODE

* Lab 1 - Akka: introduction and simple examples
** Actor-based model

The actor-bases presents several advantages
- Easier multi-threading :: No low-level concurrency constructs (like threads, shared memory, locks)
- Network transparency :: Remote objects communicate explicitly, like with local objects (and unlike RPC/RMI)
- Scalable architecture :: To guarantee elasticity

Both the OOP and Actor-based use encapsulation for state and behavior, however their main difference lays on their interaction paradigm. Consider method calls in OOP
- Multi-threading :: Multiple threads in the same local machine may directly access the same variable simultaneously
  - We need to prevent race conditions and cache problems
  - Techniques such as memory barriers, locks, condition variables are tricky and don't prevent thread blocking
    - Deadlocks :: Threads endlessly wait for each other
    - Thread contention :: Locks are expensive and can create bottlenecks
- Distributed system :: Here we have nodes and not threads, but the same problems arise in this scenario

On the other hand, with message passing in the actor model
- No direct access, no concurrency :: This removes any race condition and caching problem
- Non-blocking tasks :: Messages are non-blocking and have no return value
- Queues :: Incoming messages are queued if the receiver is busy

The core of an actor is composed by
- Message queue :: That stores incoming messages
- Dispatcher :: Reads messages from the queue and gives them to the proper handler
- Handlers :: Method that execute tasks, it can send messages to other actors
- Variables :: Describe the internal state

Implementing an actor is basically answering
- What are the messages of the system?
- What is the internal state?
- What is the mapping between incoming messages and tasks?
- How should the task be completed?

** akka

akka is a toolkit that uses the actor model to build distributed systems where
- Actors may run in different threads (one thread per actor) or computers
- Message queues are FIFO
- Send are non-blocking
- There is no guarantee on message delivery (from akka, lower layers might deal with it)
- Messages are serializable
- Deployment on a cluster is easy and scalable

*** Encapsulation problem

Java can't enforce actors encapsulation, so the programmer makes sure that no variable is accessible from multiple actors instances. For example
- Send copies of mutable objects (not their references).
- In actors, or any class used by them, static variables must be final.
- Don't use threads (or at least don't access the internal state of actor through them).

Akka implements some optimizations. For example, when messages are sent between local actors akka sends their reference, not their value.

The variable ~msg~, as any ~String~ object, is immutable. Also, it is declared as ~final~: once its value is assigned it can't be changed. In this case, the ~final~ statement prevents the reference of the object to be changed.

#+BEGIN_SRC java
public class Hello implements Serializable{
    private final String msg;
    public Hello(String msg){
	this.msg = msg;
    }
}
#+END_SRC

Assume ~ActorRef~ is immutable. Here ~group~ is mutable and ~final~, and we set its values as a copy of the argument passed to the constructor.
- ~this.group = new ArrayList<>(group)~ would not be enough: a new ~group~ would be allocated by the sender, but all the receivers would share the same reference.
- ~this.group = Collections.unmodifiableList(group)~ would not be enough either: ~unmodifiableList~ creates an unmodifiable view, so if the sender modifies ~group~ all the receivers will see the change.

#+BEGIN_SRC java
public class JoinGroupMsg implements Serializable {
    private final List<ActorRef> group;
    public JoinGroupMsg(List<ActorRef> group){
	this.group = Collections.unmodifiableList(new ArrayList<>(group));
    }
}
#+END_SRC

*** Actor

Actors are not directly instantiated by the constructor, instead the factory pattern is used: actor properties are created, defining how to instantiate the actor.

#+BEGIN_SRC java
class MyActor extends AbstractActor{
    //internal variables can be defined here
    private int id;

    //constructor
    public MyActor(int id){
	this.id = id;
    }

    //properties, used by the system to create actors
    static public Props props(int id){
	return Props.create(MyActor.class, () -> new MyActor(id));
    }
}
#+END_SRC

Initialization is as follow. Notice how an ~ActorSystem~ is used to instantiate the actor, and returns a reference to the actor.

#+BEGIN_SRC java
public static void main(String[] args) {
    //Create an actor system name "helloakka"
    final ActorSystem system = ActorSystem.create("helloakka");
    //Create an actor
    final ActorRef myactor = system.actorOf(MyActor.props(352),"actor352");
}
#+END_SRC

To send a message, we call the ~tell~ method from the destination actor reference ~myactor~ by providing the message and the sender reference (can be null to be anonymous).

#+BEGIN_SRC
Hello m = new Hello("Hi there!");
myactor.tell(m, getSelf());
#+END_SRC

To receive messages, we override the ~createReceive~ method from akka to define the mapping.
#+BEGIN_SRC java
@Override
public Receive createReceive() {
    return receiveBuilder()
	.match(Message1,class, this::onMessage1)
	.match(Message2,class, this::onMessage2)
	.match(Message3,class, this::onMessage3)
	.build();
}

private void onMessage1(Message1 msg){...}
private void onMessage2(Message1 msg){...}
private void onMessage3(Message1 msg){...}
#+END_SRC

Some useful methods are
- ~void preStart()~ (abstract) is called after actor initialization, before processing any message
- ~getSelf()~ returns ~ActorRef~ of the object itself
- ~getSelf().path().name()~ returns the name of the actor
- ~getContext().system().scheduler().schedule()~ to schedule actions
- ~getSender()~ return the reference for the current message
* Lab 2 - Akka: causal delivery & global snapshot
** Causal delivery

Here we showcase a toy group chat system, using only local actors
- Chat users :: Chat on a specific topic
- Listeners :: See all the messages, but don't chat

For such system we want to guarantee casual delivery: nobody can deliver a reply to a message before the message itself is delivered.

Remember that akka guarantees ordering only between sender and receiver (FIFO message queues), so ordering between multiple actors is not guaranteed by akka but we can do it
- Using a buffer to store received messages, that might be out of order
- Delivering the messages in order from the buffer

The order is implemented using vector clocks.
- Any sender $S$ sets first the vector clock $V_S[S] = V_S[S]+1$, then sends it with the message $m$
- $m$ is delivered to receiver $R$ only when the following conditions are met
  1. $V_S[S]=V_R[S]+1$, that is $m$ is next message that $R$ expected from $S$
  2. $V_S[i] \leq V_R[i]\ \forall i \neq S$, that is $S$ saw at most as many messages as $R$ when sending $m$
- Are the previous conditions satisfied?
  - No :: $m$ goes to the buffer
  - Yes :: Before delivering $m$, $R$ updates its vector clock $V_R$ with $V_S$

** Distributed snapshot [fn:1]

Given a generic distributed systems, we might want to take a picture that represents its state and in doing so we don't wont to disrupt the underlying computation. Assume we deal with a distributed system where
- Processes send messages through channels
- Channels are error-free
- Any message sent between a sender and a receiver is delivered in order
- Messages will eventually arrive

A snapshot should capture the state of the processes, but also the state of the channels: otherwise any message that is travelling to a receiver will be absent from the snapshot, making it inconsinstent. To overcome this situation, we may use markers/tokens to set a logical point in time.

After recording its state, a process must send a token to each outgoing channel. The full global state detection algorithm uses two rules for the marker
- Marker sending rule :: Given a process $p$, for each channel $c$ directed away from $p$, $p$ sends a marker along $c$
  - After $p$ records its state
  - Before $p$ sends any message along $c$
- Marker receiving rule :: Given a process $q$ that receives a marker along $c$, has $q$ already recorded its state?
  - No :: $q$ records its state and the state of $c$ as empty
  - Yes :: $q$ records the state of $c$ as the sequence of messages received along $c$ inbetween $q$ recording its state and receiving the marker on $c$

The procedure can be triggered by any process, and ends as soon as all the tokens are receveid by the first process.

This algorithm has been described by Chandy & Lamport in 1985. Notice that while the resulting snapshot may not correspond to any state the system was in at a given point in time, the snapshot represents a state that is logically consistent: it is guaranteed that
- It is reachable from the initial system state
- From it, we can reach the final system state

*** Bank distributed snaspshot

We have a distributed system made by banks exchanging money through channels
- Messages are just amounts of money
- The local state is the bank balance
- Given a bank, we don't need to store all the transactions but just the resulting sum

A simplified version of the original algorithm follows
- $A$ receives a token :: $A$ records its balances (if not done yet), sets ~money-in-transit~ to 0 and sends a token to all peer banks
- Bank $A$ sends a token to bank $B$ :: After $A$ records its balance, before $A$ sends any further money to $B$
- Bank $B$ receives money from bank $A$ :: If $B$ recorded its balance but received no token from $A$, $B$ sums incoming amounts to ~money-in-transit~

Some details on the akka implementation
- 10 banks starts with a balance of $1000
- Each bank sends money continuously to random peers
- There is a bank that broadcasts tokens once every second, and we can assume that a snapshot completes before another starts
- If a bank receives a token, it prints its current balance
- When the program is terminated, a output log is produced: another program checks the results of the log
However, the implementation is "faulty": the captured amount of money will not correspond to $10000, some money got lost.

The new aspect introduced by this implementation is the scheduling part: how can bank $Bank_0$ periodically take snapshots?
- By using an akka timer
- By sending a scheduled message to itself
- By delegating the ~main~ method to call a ~StartSnapshot~ of $Bank_0$

* Lab 3 - Akka: virtual synchrony

Lets define a *correct* process as one that does not fail. A *reliable multicast*, or all-or-none, for a message =m= must respect the following properties
- Validity :: If the sender is correct, =m= is delivered eventually.
- Integrity :: A process delivers =m= at most once, and only if it was previously sent.
- Agreement :: If a correct process delivers =m= then all processes deliver =m=.

In a system where the group of correct processes changes over time (join, leave, crash) members need to have a consistent view of the group. This can be achieved with *Virtual Synchrony* (*VS*), where
- Views represent a *global epoch*, since each process a maintains a view of the group and correct processes see the same sequence of views.
- Multicast messages *can't cross* epoch boundaries, so new views can be installed only as soon as all multicast from the previous group are completed (all-or-none): if a correct process delivers =m= in epoch =E=, all correct processes deliver =m= in epoch =E=.

Broadcast messages containing view changes are sent whenever a member joins or leaves the group. However, each member needs to execute an all-to-all flush to ensure all the messages from the old view have been delivered.

[[./img/vs_implementation.jpg]]

We rely on a group manager, that is the only actor that can propose view changes. This allows to manage in a single point concurrent requests and order them.

[[./img/group_manager.jpg]]

Crash are simulated as using a "crash" state and with by defining with akka a new receiver behaviour.

[[./img/crash_sim.jpg]]


* Lab 4 - Akka: 2PC


With *Two-phase commit*, a coordinator =C= decides for all nodes if a transaction should be committed or aborted (all-or-nothing atomic commit). The decision is driven by voting, requiring all partecipants to agree to execute the commit.

[[./img/2pc.jpg]]

* Footnotes

[fn:1] https://blog.acolyer.org/2015/04/22/distributed-snapshots-determining-global-states-of-distributed-systems/
